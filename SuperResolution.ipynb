{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yusuf Demir 2210356074 \n",
    "# Ender Orman 2210765011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources and Trained Models\n",
    "\n",
    "All trained models, and output results used in this notebook can be accessed via the following Google Drive link:\n",
    "\n",
    "**https://drive.google.com/drive/folders/1LtKFVcK-MQ-cy0ft0OnkRs_rpbahDMID?usp=sharing**\n",
    "\n",
    "Please make sure to mount the drive or download the necessary files before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:46:52.696110Z",
     "iopub.status.busy": "2025-05-25T11:46:52.695392Z",
     "iopub.status.idle": "2025-05-25T11:46:52.700894Z",
     "shell.execute_reply": "2025-05-25T11:46:52.700256Z",
     "shell.execute_reply.started": "2025-05-25T11:46:52.696073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Required Imports\n",
    "# -------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:46:52.869739Z",
     "iopub.status.busy": "2025-05-25T11:46:52.869560Z",
     "iopub.status.idle": "2025-05-25T11:46:53.807315Z",
     "shell.execute_reply": "2025-05-25T11:46:53.806617Z",
     "shell.execute_reply.started": "2025-05-25T11:46:52.869725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Custom Dataset Class for LOL Dataset\n",
    "# -------------------------------------------\n",
    "class LOLDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"our485\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Define low and high light directories\n",
    "        self.low_light_dir = os.path.join(root_dir, split, \"low\")\n",
    "        self.high_light_dir = os.path.join(root_dir, split, \"high\")\n",
    "\n",
    "        # Filter valid image extensions\n",
    "        valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "        self.image_names = [\n",
    "            f for f in os.listdir(self.low_light_dir) if f.lower().endswith(valid_extensions)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of image pairs\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image filenames for both low and high light versions\n",
    "        img_name = self.image_names[idx]\n",
    "        low_light_path = os.path.join(self.low_light_dir, img_name)\n",
    "        high_light_path = os.path.join(self.high_light_dir, img_name)\n",
    "\n",
    "        # Open both images and convert to RGB\n",
    "        low_light_image = Image.open(low_light_path).convert(\"RGB\")\n",
    "        high_light_image = Image.open(high_light_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            low_light_image = self.transform(low_light_image)\n",
    "            high_light_image = self.transform(high_light_image)\n",
    "\n",
    "        return low_light_image, high_light_image\n",
    "\n",
    "# -------------------------------------------\n",
    "# Image Transformations\n",
    "# -------------------------------------------\n",
    "# Resizing all images to the same size and converting them to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load LOL Dataset\n",
    "# -------------------------------------------\n",
    "# Using 'our485' for training\n",
    "dataset = LOLDataset(root_dir=\"/kaggle/input/loldataset\", split=\"our485\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Visualization Function\n",
    "# -------------------------------------------\n",
    "def show_samples():\n",
    "    # Load a batch of samples\n",
    "    low_images, high_images = next(iter(dataloader))\n",
    "    \n",
    "    # Plot low-light (top row) and high-light (bottom row) image pairs\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "    for i in range(4):\n",
    "        axes[0, i].imshow(low_images[i].permute(1, 2, 0))\n",
    "        axes[0, i].set_title(\"Low Light\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        axes[1, i].imshow(high_images[i].permute(1, 2, 0))\n",
    "        axes[1, i].set_title(\"High Light\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------\n",
    "# Show Sample Images\n",
    "# -------------------------------------------\n",
    "show_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:46:55.687098Z",
     "iopub.status.busy": "2025-05-25T11:46:55.686433Z",
     "iopub.status.idle": "2025-05-25T11:47:21.608576Z",
     "shell.execute_reply": "2025-05-25T11:47:21.607778Z",
     "shell.execute_reply.started": "2025-05-25T11:46:55.687070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_average_ssim_between_low_and_high(root_dir, resize_to=(256, 256)):\n",
    "    low_dir = os.path.join(root_dir, \"our485\", \"low\")\n",
    "    high_dir = os.path.join(root_dir, \"our485\", \"high\")\n",
    "\n",
    "    filenames = sorted([\n",
    "        f for f in os.listdir(low_dir)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ])\n",
    "\n",
    "    total_ssim = 0\n",
    "    count = 0\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.Resize(resize_to),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    for name in tqdm(filenames, desc=\"Calculating SSIM\"):\n",
    "        low_path = os.path.join(low_dir, name)\n",
    "        high_path = os.path.join(high_dir, name)\n",
    "\n",
    "        if not os.path.exists(high_path):\n",
    "            continue\n",
    "\n",
    "        low_img = transform(Image.open(low_path).convert(\"RGB\")).numpy().transpose(1, 2, 0)\n",
    "        high_img = transform(Image.open(high_path).convert(\"RGB\")).numpy().transpose(1, 2, 0)\n",
    "\n",
    "        win_size = min(low_img.shape[0], low_img.shape[1], 7)\n",
    "\n",
    "        score = ssim(low_img, high_img, data_range=1, channel_axis=2, win_size=win_size)\n",
    "        total_ssim += score\n",
    "        count += 1\n",
    "\n",
    "    avg_ssim = total_ssim / count if count > 0 else 0\n",
    "    print(f\"\\nAverage SSIM between low-light and high-light images: {avg_ssim:.4f}\")\n",
    "    return avg_ssim\n",
    "\n",
    "compute_average_ssim_between_low_and_high(\"/kaggle/input/loldataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:21.609993Z",
     "iopub.status.busy": "2025-05-25T11:47:21.609786Z",
     "iopub.status.idle": "2025-05-25T11:47:21.615435Z",
     "shell.execute_reply": "2025-05-25T11:47:21.614794Z",
     "shell.execute_reply.started": "2025-05-25T11:47:21.609977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super(SRCNN, self).__init__()\n",
    "        \n",
    "        # First convolution layer: large kernel to extract features from low-resolution image\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=9, padding=4)\n",
    "        \n",
    "        # Second layer: map high-dimensional features to a lower-dimensional space\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        \n",
    "        # Final layer: reconstruct the high-resolution image\n",
    "        self.conv3 = nn.Conv2d(32, output_channels, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x + residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:21.616276Z",
     "iopub.status.busy": "2025-05-25T11:47:21.616061Z",
     "iopub.status.idle": "2025-05-25T11:47:21.634030Z",
     "shell.execute_reply": "2025-05-25T11:47:21.633487Z",
     "shell.execute_reply.started": "2025-05-25T11:47:21.616256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Residual block for deeper learning\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "# Improved SRCNN with upsampling and residual blocks\n",
    "class EnhancedSRCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, upscale_factor=2):\n",
    "        super(EnhancedSRCNN, self).__init__()\n",
    "\n",
    "        self.entry = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=9, padding=4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.resblock1 = ResidualBlock(64)\n",
    "        self.resblock2 = ResidualBlock(64)\n",
    "\n",
    "        # Output layer\n",
    "        self.exit = nn.Conv2d(64, output_channels, kernel_size=5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.exit(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:21.635580Z",
     "iopub.status.busy": "2025-05-25T11:47:21.635341Z",
     "iopub.status.idle": "2025-05-25T11:47:21.650000Z",
     "shell.execute_reply": "2025-05-25T11:47:21.649220Z",
     "shell.execute_reply.started": "2025-05-25T11:47:21.635565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "# Squeeze-and-Excitation Block (Channel Attention)\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.pool(x)\n",
    "        scale = self.fc(scale)\n",
    "        return x * scale\n",
    "\n",
    "# Enhanced SRCNN v2\n",
    "class EnhancedSRCNNv2(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super(EnhancedSRCNNv2, self).__init__()\n",
    "\n",
    "        self.entry = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=9, padding=4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.resblock1 = ResidualBlock(64)\n",
    "        self.resblock2 = ResidualBlock(64)\n",
    "        self.att1 = SEBlock(64)\n",
    "\n",
    "        self.resblock3 = ResidualBlock(64)\n",
    "        self.resblock4 = ResidualBlock(64)\n",
    "        self.att2 = SEBlock(64)\n",
    "\n",
    "        self.exit = nn.Conv2d(64, output_channels, kernel_size=5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.att1(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.att2(x)\n",
    "        x = self.exit(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:21.650776Z",
     "iopub.status.busy": "2025-05-25T11:47:21.650579Z",
     "iopub.status.idle": "2025-05-25T11:47:21.664787Z",
     "shell.execute_reply": "2025-05-25T11:47:21.664074Z",
     "shell.execute_reply.started": "2025-05-25T11:47:21.650761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "\n",
    "        # Channel Attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction_ratio, channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ----- Channel Attention -----\n",
    "        avg_out = self.channel_attention(self.avg_pool(x))\n",
    "        max_out = self.channel_attention(self.max_pool(x))\n",
    "        channel_attention = self.sigmoid_channel(avg_out + max_out)\n",
    "        x = x * channel_attention\n",
    "\n",
    "        # ----- Spatial Attention -----\n",
    "        avg_channel = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_channel, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_input = torch.cat([avg_channel, max_channel], dim=1)\n",
    "        spatial_attention = self.spatial_attention(spatial_input)\n",
    "        x = x * spatial_attention\n",
    "\n",
    "        return x\n",
    "\n",
    "class YASRNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(YASRNet, self).__init__()\n",
    "\n",
    "        self.entry = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 9, padding=4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block1 = ResidualBlock(64)\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.cbam1 = CBAMBlock(64)\n",
    "\n",
    "        self.block3 = ResidualBlock(64)\n",
    "        self.block4 = ResidualBlock(64)\n",
    "        self.cbam2 = CBAMBlock(64)\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.out = nn.Conv2d(64, out_channels, 5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.cbam1(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.cbam2(x)\n",
    "        x = self.upsample(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:21.665550Z",
     "iopub.status.busy": "2025-05-25T11:47:21.665387Z",
     "iopub.status.idle": "2025-05-25T11:47:21.681764Z",
     "shell.execute_reply": "2025-05-25T11:47:21.681263Z",
     "shell.execute_reply.started": "2025-05-25T11:47:21.665538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Model Training Function\n",
    "# --------------------------\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=10, lr=0.001, model_name=\"SRCNN\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_wts = None\n",
    "    loss_history = []\n",
    "\n",
    "    # Create output dirs\n",
    "    os.makedirs(\"saved_models\", exist_ok=True)\n",
    "    os.makedirs(\"Metrics\", exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics_dir = os.path.join(\"Metrics\", f\"{model_name}_{timestamp}\")\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for low_light, high_light in dataloader:\n",
    "            low_light, high_light = low_light.to(device), high_light.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(low_light)\n",
    "\n",
    "            if outputs.size() != high_light.size():\n",
    "                high_light = F.interpolate(high_light, size=outputs.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            loss = criterion(outputs, high_light)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # Save best model\n",
    "    if best_model_wts:\n",
    "        filename = f\"{model_name}_{num_epochs}e_best.pth\"\n",
    "        save_path = os.path.join(\"saved_models\", filename)\n",
    "        torch.save(best_model_wts, save_path)\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Save loss plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o', color='blue')\n",
    "    plt.title(f\"{model_name} Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f\"{model_name}_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Loss plot saved to '{metrics_dir}/'.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:23.166912Z",
     "iopub.status.busy": "2025-05-25T11:47:23.166651Z",
     "iopub.status.idle": "2025-05-25T11:47:23.173327Z",
     "shell.execute_reply": "2025-05-25T11:47:23.172551Z",
     "shell.execute_reply.started": "2025-05-25T11:47:23.166892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Visualization Function (Low-Memory Safe)\n",
    "# --------------------------\n",
    "\n",
    "def test_model(model, low_light, high_light, max_visualize=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Restrict batch size to first N samples\n",
    "    low_light = low_light[:max_visualize].to(device)\n",
    "    high_light = high_light[:max_visualize].to(\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(low_light).cpu()\n",
    "\n",
    "    # Plot the selected samples\n",
    "    fig, axes = plt.subplots(3, max_visualize, figsize=(4 * max_visualize, 8))\n",
    "\n",
    "    for i in range(max_visualize):\n",
    "        axes[0, i].imshow(low_light[i].cpu().permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[0, i].set_title(\"Low Light\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        axes[1, i].imshow(outputs[i].permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[1, i].set_title(\"Super Resolution\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "        axes[2, i].imshow(high_light[i].permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[2, i].set_title(\"Ground Truth\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:23.434577Z",
     "iopub.status.busy": "2025-05-25T11:47:23.434355Z",
     "iopub.status.idle": "2025-05-25T11:47:23.442090Z",
     "shell.execute_reply": "2025-05-25T11:47:23.441544Z",
     "shell.execute_reply.started": "2025-05-25T11:47:23.434560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Evaluation Metrics: PSNR & SSIM\n",
    "# --------------------------\n",
    "\n",
    "# We will keep all trials here globally\n",
    "performance_log = []\n",
    "\n",
    "def evaluate_performance(model, dataloader, model_name=\"SRCNN\", epoch_count=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    psnr_scores = []\n",
    "    ssim_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for low_light, high_light in dataloader:\n",
    "            low_light, high_light = low_light.to(device), high_light.to(device)\n",
    "            outputs = model(low_light)\n",
    "\n",
    "            for i in range(outputs.size(0)):\n",
    "                output = outputs[i]\n",
    "                target = high_light[i]\n",
    "\n",
    "                # Match size if needed\n",
    "                if output.shape[-2:] != target.shape[-2:]:\n",
    "                    target = F.interpolate(target.unsqueeze(0), size=output.shape[-2:], mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "                # Convert to numpy\n",
    "                pred = output.cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "                gt = target.cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "\n",
    "                h, w, _ = gt.shape\n",
    "                win_size = min(h, w, 7)\n",
    "\n",
    "                psnr_scores.append(psnr(gt, pred, data_range=1))\n",
    "                ssim_scores.append(ssim(gt, pred, data_range=1, win_size=win_size, channel_axis=2))\n",
    "\n",
    "    mean_psnr = np.mean(psnr_scores)\n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "\n",
    "    print(f\"\\nArchitecture: {model_name}, Epochs: {epoch_count}\")\n",
    "    print(f\"Average PSNR: {mean_psnr:.2f}\")\n",
    "    print(f\"Average SSIM: {mean_ssim:.4f}\")\n",
    "\n",
    "    # Save to global log\n",
    "    performance_log.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Epochs\": epoch_count,\n",
    "        \"PSNR\": round(mean_psnr, 2),\n",
    "        \"SSIM\": round(mean_ssim, 4)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:24.574531Z",
     "iopub.status.busy": "2025-05-25T11:47:24.574272Z",
     "iopub.status.idle": "2025-05-25T11:47:24.580472Z",
     "shell.execute_reply": "2025-05-25T11:47:24.579717Z",
     "shell.execute_reply.started": "2025-05-25T11:47:24.574514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compare_all_models():\n",
    "    if not performance_log:\n",
    "        print(\"No evaluations logged yet.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(performance_log)\n",
    "    df_sorted = df.sort_values(by=\"SSIM\", ascending=False)\n",
    "\n",
    "    print(\"\\n Model Performance Comparison:\")\n",
    "    print(df_sorted.to_string(index=False))\n",
    "\n",
    "    # Create bar chart for SSIM and PSNR\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # SSIM plot\n",
    "    ax[0].bar(df_sorted[\"Model\"] + \" (\" + df_sorted[\"Epochs\"].astype(str) + \"e)\", df_sorted[\"SSIM\"], color=\"skyblue\")\n",
    "    ax[0].set_title(\"SSIM Comparison\")\n",
    "    ax[0].set_ylabel(\"SSIM Score\")\n",
    "    ax[0].set_ylim(0, 1)\n",
    "    ax[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # PSNR plot\n",
    "    ax[1].bar(df_sorted[\"Model\"] + \" (\" + df_sorted[\"Epochs\"].astype(str) + \"e)\", df_sorted[\"PSNR\"], color=\"salmon\")\n",
    "    ax[1].set_title(\"PSNR Comparison\")\n",
    "    ax[1].set_ylabel(\"PSNR (dB)\")\n",
    "    ax[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:27.505925Z",
     "iopub.status.busy": "2025-05-25T11:47:27.505643Z",
     "iopub.status.idle": "2025-05-25T11:47:27.509707Z",
     "shell.execute_reply": "2025-05-25T11:47:27.509052Z",
     "shell.execute_reply.started": "2025-05-25T11:47:27.505905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# --------- Global Configurations ----------\n",
    "NUM_EPOCH = 30\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "performance_log = []\n",
    "training_times = {}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:47:31.165962Z",
     "iopub.status.busy": "2025-05-25T11:47:31.165704Z",
     "iopub.status.idle": "2025-05-25T12:05:47.193737Z",
     "shell.execute_reply": "2025-05-25T12:05:47.192916Z",
     "shell.execute_reply.started": "2025-05-25T11:47:31.165943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining SRCNN...\")\n",
    "\n",
    "start_time = time.time()\n",
    "model_srcnn = SRCNN()\n",
    "trained_srcnn = train_model(\n",
    "    model_srcnn,\n",
    "    dataloader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    lr=LR,\n",
    "    model_name=\"SRCNN\"\n",
    ")\n",
    "training_times[\"SRCNN\"] = time.time() - start_time\n",
    "trained_models[\"SRCNN\"] = trained_srcnn\n",
    "\n",
    "# Fixed test batch\n",
    "fixed_batch = next(iter(DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)))\n",
    "low_light_batch, high_light_batch = fixed_batch\n",
    "\n",
    "print(\"\\nVisual Comparison: SRCNN\")\n",
    "test_model(trained_srcnn, low_light_batch, high_light_batch)\n",
    "\n",
    "evaluate_performance(trained_srcnn, dataloader, model_name=\"SRCNN\", epoch_count=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:05:47.195252Z",
     "iopub.status.busy": "2025-05-25T12:05:47.194984Z",
     "iopub.status.idle": "2025-05-25T12:33:54.053553Z",
     "shell.execute_reply": "2025-05-25T12:33:54.052811Z",
     "shell.execute_reply.started": "2025-05-25T12:05:47.195233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining EnhancedSRCNN...\")\n",
    "\n",
    "start_time = time.time()\n",
    "model_enhanced = EnhancedSRCNN()\n",
    "trained_enhanced = train_model(\n",
    "    model_enhanced,\n",
    "    dataloader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    lr=LR,\n",
    "    model_name=\"EnhancedSRCNN\"\n",
    ")\n",
    "training_times[\"EnhancedSRCNN\"] = time.time() - start_time\n",
    "trained_models[\"EnhancedSRCNN\"] = trained_enhanced\n",
    "\n",
    "# Aynı test batch'i kullan\n",
    "print(\"\\nVisual Comparison: EnhancedSRCNN\")\n",
    "test_model(trained_enhanced, low_light_batch, high_light_batch)\n",
    "\n",
    "evaluate_performance(trained_enhanced, dataloader, model_name=\"EnhancedSRCNN\", epoch_count=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:33:54.054515Z",
     "iopub.status.busy": "2025-05-25T12:33:54.054318Z",
     "iopub.status.idle": "2025-05-25T13:16:32.085208Z",
     "shell.execute_reply": "2025-05-25T13:16:32.084454Z",
     "shell.execute_reply.started": "2025-05-25T12:33:54.054500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining EnhancedSRCNNv2...\")\n",
    "start_time = time.time()\n",
    "model_v2 = EnhancedSRCNNv2()\n",
    "trained_v2 = train_model(model_v2, dataloader, NUM_EPOCH, LR, \"EnhancedSRCNNv2\")\n",
    "training_times[\"EnhancedSRCNNv2\"] = time.time() - start_time\n",
    "trained_models[\"EnhancedSRCNNv2\"] = trained_v2\n",
    "\n",
    "print(\"\\nVisual Comparison: EnhancedSRCNNv2\")\n",
    "test_model(trained_v2, low_light_batch, high_light_batch)\n",
    "evaluate_performance(trained_v2, dataloader, model_name=\"EnhancedSRCNNv2\", epoch_count=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T13:16:32.087024Z",
     "iopub.status.busy": "2025-05-25T13:16:32.086723Z",
     "iopub.status.idle": "2025-05-25T14:36:51.722817Z",
     "shell.execute_reply": "2025-05-25T14:36:51.722085Z",
     "shell.execute_reply.started": "2025-05-25T13:16:32.087005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining YASRNet...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_yasr = YASRNet()\n",
    "trained_yasr = train_model(\n",
    "    model_yasr,\n",
    "    dataloader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    lr=LR,\n",
    "    model_name=\"YASRNet\"\n",
    ")\n",
    "\n",
    "training_times[\"YASRNet\"] = time.time() - start_time\n",
    "trained_models[\"YASRNet\"] = trained_yasr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:36:51.723997Z",
     "iopub.status.busy": "2025-05-25T14:36:51.723756Z",
     "iopub.status.idle": "2025-05-25T14:39:12.400006Z",
     "shell.execute_reply": "2025-05-25T14:39:12.399211Z",
     "shell.execute_reply.started": "2025-05-25T14:36:51.723980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test visualization (comparison with the same batch)\n",
    "print(\"\\nVisual Comparison: YASRNet\")\n",
    "test_model(trained_yasr, low_light_batch, high_light_batch, max_visualize=4)\n",
    "\n",
    "# Performance evaluation (PSNR + SSIM)\n",
    "evaluate_performance(trained_yasr, dataloader, model_name=\"YASRNet\", epoch_count=NUM_EPOCH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duruma göre alttaki silinecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:39:12.400809Z",
     "iopub.status.busy": "2025-05-25T14:39:12.400591Z",
     "iopub.status.idle": "2025-05-25T14:39:12.405147Z",
     "shell.execute_reply": "2025-05-25T14:39:12.404425Z",
     "shell.execute_reply.started": "2025-05-25T14:39:12.400791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Example: How to Load a Pretrained Model\n",
    "# --------------------------------------------\n",
    "\n",
    "# # 1. Make sure the model class is defined\n",
    "# model = YASRNet()\n",
    "\n",
    "# # 2. Load the saved best weights\n",
    "# model.load_state_dict(torch.load(\"/kaggle/working/saved_models/YASRNet_30e_best.pth\",\n",
    "#                                  map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# # 3. Set the model to evaluation mode and move to device\n",
    "# model = model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # 4. Register the model to dictionary (optional)\n",
    "# trained_models[\"YASRNet\"] = model\n",
    "\n",
    "# # 5. Evaluate model performance (e.g., PSNR + SSIM)\n",
    "# evaluate_performance(model, dataloader, model_name=\"YASRNet\", epoch_count=NUM_EPOCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge-Aware Loss for Better Detection\n",
    "\n",
    "In this experiment, we update the loss function by combining the traditional MSE loss with an edge-based loss using the Laplacian filter. The goal is to preserve sharp structures and edges in the super-resolved images.\n",
    "\n",
    "Although this may lead to slightly lower SSIM scores (since the overall pixel similarity may decrease), we expect object detection performance to improve. This is because detectors like YOLO rely more on edges and object boundaries rather than smooth textures.\n",
    "\n",
    "**Total Loss = 0.8 × MSE + 0.2 × Edge Loss (Laplacian)**\n",
    "\n",
    "This loss encourages the model to generate outputs that are not only close to the ground truth but also maintain important edge details for better semantic understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:39:12.406410Z",
     "iopub.status.busy": "2025-05-25T14:39:12.406080Z",
     "iopub.status.idle": "2025-05-25T14:39:12.429449Z",
     "shell.execute_reply": "2025-05-25T14:39:12.428859Z",
     "shell.execute_reply.started": "2025-05-25T14:39:12.406391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_laplacian_kernel(device):\n",
    "    lap = torch.tensor([[0, 1, 0],\n",
    "                        [1, -4, 1],\n",
    "                        [0, 1, 0]], dtype=torch.float32)\n",
    "    kernel = lap.unsqueeze(0).unsqueeze(0)  # (1, 1, 3, 3)\n",
    "    return kernel.to(device)\n",
    "\n",
    "\n",
    "def train_model_edge_mse(model, dataloader, num_epochs=10, lr=0.001, model_name=\"SR_EdgeMSE\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    mse_loss_fn = nn.MSELoss()\n",
    "    laplacian_kernel = get_laplacian_kernel(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_wts = None\n",
    "    loss_history = []\n",
    "\n",
    "    # Output dirs\n",
    "    os.makedirs(\"saved_models\", exist_ok=True)\n",
    "    os.makedirs(\"Metrics\", exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics_dir = os.path.join(\"Metrics\", f\"{model_name}_{timestamp}\")\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for low_light, high_light in dataloader:\n",
    "            low_light, high_light = low_light.to(device), high_light.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(low_light)\n",
    "\n",
    "            if outputs.shape != high_light.shape:\n",
    "                high_light = F.interpolate(high_light, size=outputs.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            # MSE Loss\n",
    "            mse = mse_loss_fn(outputs, high_light)\n",
    "\n",
    "            # Edge Loss (Laplacian)\n",
    "            edge_sr = F.conv2d(outputs, laplacian_kernel.expand(outputs.size(1), -1, -1, -1),\n",
    "                               padding=1, groups=outputs.size(1))\n",
    "            edge_gt = F.conv2d(high_light, laplacian_kernel.expand(high_light.size(1), -1, -1, -1),\n",
    "                               padding=1, groups=high_light.size(1))\n",
    "            edge_loss = mse_loss_fn(edge_sr, edge_gt)\n",
    "\n",
    "            # Total Loss\n",
    "            total = 0.8 * mse + 0.2 * edge_loss\n",
    "            total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += total.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # Save best model\n",
    "    if best_model_wts:\n",
    "        save_path = os.path.join(\"saved_models\", f\"{model_name}_{num_epochs}e_best.pth\")\n",
    "        torch.save(best_model_wts, save_path)\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o', color='purple')\n",
    "    plt.title(f\"{model_name} Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE + Edge)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f\"{model_name}_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Metrics saved to '{metrics_dir}/'\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:39:12.430438Z",
     "iopub.status.busy": "2025-05-25T14:39:12.430197Z",
     "iopub.status.idle": "2025-05-25T14:57:33.771461Z",
     "shell.execute_reply": "2025-05-25T14:57:33.770680Z",
     "shell.execute_reply.started": "2025-05-25T14:39:12.430416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining SRCNN (MSE + Edge Loss)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_srcnn = SRCNN()\n",
    "trained_srcnn = train_model_edge_mse(\n",
    "    model_srcnn,\n",
    "    dataloader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    lr=LR,\n",
    "    model_name=\"SRCNN_Edge\"\n",
    ")\n",
    "\n",
    "training_times[\"SRCNN_Edge\"] = time.time() - start_time\n",
    "trained_models[\"SRCNN_Edge\"] = trained_srcnn\n",
    "\n",
    "# Fixed test batch (değişmedi)\n",
    "fixed_batch = next(iter(DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)))\n",
    "low_light_batch, high_light_batch = fixed_batch\n",
    "\n",
    "print(\"\\nVisual Comparison: SRCNN_Edge\")\n",
    "test_model(trained_srcnn, low_light_batch, high_light_batch)\n",
    "\n",
    "evaluate_performance(trained_srcnn, dataloader, model_name=\"SRCNN_Edge\", epoch_count=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:57:33.772671Z",
     "iopub.status.busy": "2025-05-25T14:57:33.772404Z",
     "iopub.status.idle": "2025-05-25T14:57:33.777733Z",
     "shell.execute_reply": "2025-05-25T14:57:33.776987Z",
     "shell.execute_reply.started": "2025-05-25T14:57:33.772644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Trained model names\n",
    "print(\"Trained Models:\")\n",
    "print(list(trained_models.keys()))\n",
    "\n",
    "# 2. Training periods\n",
    "print(\"\\nTraining Time Summary:\")\n",
    "for model_name, duration in training_times.items():\n",
    "    print(f\"{model_name}: {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:57:33.779667Z",
     "iopub.status.busy": "2025-05-25T14:57:33.779452Z",
     "iopub.status.idle": "2025-05-25T14:57:34.102142Z",
     "shell.execute_reply": "2025-05-25T14:57:34.101502Z",
     "shell.execute_reply.started": "2025-05-25T14:57:33.779643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_all_models()\n",
    "\n",
    "# Choose the best model by SSIM\n",
    "best_model_name = max(performance_log, key=lambda x: x[\"SSIM\"])[\"Model\"]\n",
    "print(f\"\\nUsing best SR model based on SSIM: {best_model_name}\")\n",
    "best_model = trained_models[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM Evaluation Result\n",
    "\n",
    "Among all tested models, **YASRNet achieved the highest SSIM score (0.8367)**.  \n",
    "This is likely due to its deeper structure and attention modules (CBAM), which help preserve fine details and textures in the image.  \n",
    "Other models, including edge-aware SRCNN, focus more on structural sharpness but may sacrifice overall similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T14:57:59.831660Z",
     "iopub.status.busy": "2025-05-25T14:57:59.831379Z",
     "iopub.status.idle": "2025-05-25T15:02:03.119507Z",
     "shell.execute_reply": "2025-05-25T15:02:03.118836Z",
     "shell.execute_reply.started": "2025-05-25T14:57:59.831640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create SRresults folder and save results\n",
    "import torchvision.transforms as T\n",
    "import shutil\n",
    "\n",
    "output_dir = \"SRresults\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(\"old folder deleted\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "ordered_dataset = LOLDataset(root_dir=\"/kaggle/input/loldataset\", split=\"our485\", transform=transform)\n",
    "ordered_loader = DataLoader(ordered_dataset, batch_size=4, shuffle=False)\n",
    "image_names = ordered_dataset.image_names\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (low_img, _) in enumerate(ordered_loader):\n",
    "        low_img = low_img.to(device)\n",
    "        sr_output = best_model(low_img)\n",
    "\n",
    "        for i in range(sr_output.size(0)):\n",
    "            img_tensor = sr_output[i].cpu().clamp(0, 1)\n",
    "            img_pil = T.ToPILImage()(img_tensor)\n",
    "            filename = image_names[idx * ordered_loader.batch_size + i]\n",
    "            img_pil.save(os.path.join(output_dir, filename))\n",
    "\n",
    "print(f\"\\nSR images saved to '{output_dir}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:02:03.121270Z",
     "iopub.status.busy": "2025-05-25T15:02:03.120767Z",
     "iopub.status.idle": "2025-05-25T15:02:03.124649Z",
     "shell.execute_reply": "2025-05-25T15:02:03.124072Z",
     "shell.execute_reply.started": "2025-05-25T15:02:03.121248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model = trained_models[\"SRCNN_Edge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:02:03.125496Z",
     "iopub.status.busy": "2025-05-25T15:02:03.125335Z",
     "iopub.status.idle": "2025-05-25T15:03:24.481513Z",
     "shell.execute_reply": "2025-05-25T15:03:24.480816Z",
     "shell.execute_reply.started": "2025-05-25T15:02:03.125483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create SRresults folder and save results\n",
    "import torchvision.transforms as T\n",
    "import shutil\n",
    "\n",
    "output_dir = \"SRresults_edge\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(\"old folder deleted\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "ordered_dataset = LOLDataset(root_dir=\"/kaggle/input/loldataset\", split=\"our485\", transform=transform)\n",
    "ordered_loader = DataLoader(ordered_dataset, batch_size=4, shuffle=False)\n",
    "image_names = ordered_dataset.image_names\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (low_img, _) in enumerate(ordered_loader):\n",
    "        low_img = low_img.to(device)\n",
    "        sr_output = best_model(low_img)\n",
    "\n",
    "        for i in range(sr_output.size(0)):\n",
    "            img_tensor = sr_output[i].cpu().clamp(0, 1)\n",
    "            img_pil = T.ToPILImage()(img_tensor)\n",
    "            filename = image_names[idx * ordered_loader.batch_size + i]\n",
    "            img_pil.save(os.path.join(output_dir, filename))\n",
    "\n",
    "print(f\"\\nSR images saved to '{output_dir}/'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8l for Object Detection Evaluation\n",
    "\n",
    "We use the pre-trained **YOLOv8l** (large) model to evaluate object detection performance on different versions of the same image:\n",
    "- Low-light image\n",
    "- Super-resolved image (enhanced from low-light)\n",
    "- Ground-truth high-light image\n",
    "\n",
    "YOLOv8l is selected because:\n",
    "- It offers strong object detection accuracy out-of-the-box.\n",
    "- It works well in complex indoor scenes without requiring fine-tuning.\n",
    "- It balances performance and speed effectively on GPU.\n",
    "\n",
    "In this project, we do **not fine-tune** YOLO. Instead, we directly apply the pre-trained model to all image types and compare the number of detected objects and confidence scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:13:50.862497Z",
     "iopub.status.busy": "2025-05-25T15:13:50.861819Z",
     "iopub.status.idle": "2025-05-25T15:13:51.652397Z",
     "shell.execute_reply": "2025-05-25T15:13:51.651647Z",
     "shell.execute_reply.started": "2025-05-25T15:13:50.862475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8m pre-trained model\n",
    "model = YOLO(\"yolov8l.pt\")  \n",
    "\n",
    "# Inference on an image or tensor\n",
    "results = model(\"/kaggle/input/loldataset/our485/high/103.png\")  # Replace with your image path\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:13:51.653739Z",
     "iopub.status.busy": "2025-05-25T15:13:51.653532Z",
     "iopub.status.idle": "2025-05-25T15:13:52.428122Z",
     "shell.execute_reply": "2025-05-25T15:13:52.427411Z",
     "shell.execute_reply.started": "2025-05-25T15:13:51.653723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Detection Comparison Function (Flexible SR folder)\n",
    "# --------------------------\n",
    "\n",
    "def compare_detections(model, image_id, sr_dir=\"/kaggle/working/SRresults\"):\n",
    "    \"\"\"\n",
    "    Performs YOLOv8 detection on high-light, low-light, and SR versions of the same image.\n",
    "    Shows bounding boxes for visual comparison.\n",
    "\n",
    "    Parameters:\n",
    "        model: Pretrained YOLOv8 model\n",
    "        image_id: Image file name, e.g., \"5.png\"\n",
    "        sr_dir: Path to super-resolved image folder (default: '/kaggle/working/SRresults')\n",
    "    \"\"\"\n",
    "\n",
    "    # Define full paths\n",
    "    high_path = f\"/kaggle/input/loldataset/our485/high/{image_id}\"\n",
    "    low_path = f\"/kaggle/input/loldataset/our485/low/{image_id}\"\n",
    "    sr_path = os.path.join(sr_dir, image_id)\n",
    "\n",
    "    # Perform inference\n",
    "    print(f\"\\nHigh-light image: {image_id}\")\n",
    "    high_result = model(high_path)[0]\n",
    "    high_result.show()\n",
    "\n",
    "    print(f\"\\nLow-light image: {image_id}\")\n",
    "    low_result = model(low_path)[0]\n",
    "    low_result.show()\n",
    "\n",
    "    print(f\"\\nSuper-resolved image: {image_id}\")\n",
    "    sr_result = model(sr_path)[0]\n",
    "    sr_result.show()\n",
    "\n",
    "compare_detections(model, \"5.png\")\n",
    "compare_detections(model, \"5.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T15:11:17.080000Z",
     "iopub.status.busy": "2025-05-25T15:11:17.079734Z",
     "iopub.status.idle": "2025-05-25T15:12:27.854854Z",
     "shell.execute_reply": "2025-05-25T15:12:27.854253Z",
     "shell.execute_reply.started": "2025-05-25T15:11:17.079980Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_detection_performance(\n",
    "    model,\n",
    "    sr_dir=\"/kaggle/working/SRresults\",\n",
    "    csv_path=\"detection_results.csv\",\n",
    "    confidence_threshold=0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs YOLO detection on low-light, high-light, and SR images and saves results to CSV.\n",
    "    Also prints total detection counts for each image type.\n",
    "\n",
    "    Parameters:\n",
    "        model: Pretrained YOLO model\n",
    "        sr_dir: Folder containing super-resolved images (default: '/kaggle/working/SRresults')\n",
    "        csv_path: Output CSV file name (default: 'detection_results.csv')\n",
    "        confidence_threshold: Minimum confidence to count a detection (default: 0.8)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "\n",
    "    low_dir = \"/kaggle/input/loldataset/our485/low\"\n",
    "    high_dir = \"/kaggle/input/loldataset/our485/high\"\n",
    "\n",
    "    # Backup existing CSV\n",
    "    if os.path.exists(csv_path):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        new_name = f\"{csv_path.split('.')[0]}_{timestamp}.csv\"\n",
    "        os.rename(csv_path, new_name)\n",
    "        print(f\"Previous '{csv_path}' found. Renamed to '{new_name}'.\")\n",
    "\n",
    "    results = []\n",
    "    image_names = sorted(os.listdir(low_dir))\n",
    "\n",
    "    total_low, total_sr, total_high = 0, 0, 0\n",
    "\n",
    "    for name in image_names:\n",
    "        row = {\"image\": name}\n",
    "\n",
    "        # Low-light image\n",
    "        low_path = os.path.join(low_dir, name)\n",
    "        low_result = model(low_path)[0]\n",
    "        low_conf = low_result.boxes.conf.cpu() if len(low_result.boxes) > 0 else torch.tensor([])\n",
    "        low_mask = low_conf >= confidence_threshold\n",
    "        low_count = int(low_mask.sum())\n",
    "        total_low += low_count\n",
    "        row[\"low_detections\"] = low_count\n",
    "        row[\"low_conf_avg\"] = float(low_conf[low_mask].mean().item()) if low_count > 0 else 0\n",
    "\n",
    "        # Super-resolved image\n",
    "        sr_path = os.path.join(sr_dir, name)\n",
    "        if os.path.exists(sr_path):\n",
    "            sr_result = model(sr_path)[0]\n",
    "            sr_conf = sr_result.boxes.conf.cpu() if len(sr_result.boxes) > 0 else torch.tensor([])\n",
    "            sr_mask = sr_conf >= confidence_threshold\n",
    "            sr_count = int(sr_mask.sum())\n",
    "            total_sr += sr_count\n",
    "            row[\"sr_detections\"] = sr_count\n",
    "            row[\"sr_conf_avg\"] = float(sr_conf[sr_mask].mean().item()) if sr_count > 0 else 0\n",
    "        else:\n",
    "            row[\"sr_detections\"] = None\n",
    "            row[\"sr_conf_avg\"] = None\n",
    "\n",
    "        # High-light image\n",
    "        high_path = os.path.join(high_dir, name)\n",
    "        high_result = model(high_path)[0]\n",
    "        high_conf = high_result.boxes.conf.cpu() if len(high_result.boxes) > 0 else torch.tensor([])\n",
    "        high_mask = high_conf >= confidence_threshold\n",
    "        high_count = int(high_mask.sum())\n",
    "        total_high += high_count\n",
    "        row[\"high_detections\"] = high_count\n",
    "        row[\"high_conf_avg\"] = float(high_conf[high_mask].mean().item()) if high_count > 0 else 0\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    # Save results to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nResults saved to {csv_path} (conf ≥ {confidence_threshold})\")\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nTotal Detections Summary:\")\n",
    "    print(f\"- Low-light images:      {total_low} detections\")\n",
    "    print(f\"- Super-resolved images: {total_sr} detections\")\n",
    "    print(f\"- High-light images:     {total_high} detections\")\n",
    "\n",
    "\n",
    "# Varsayılan SR klasörüyle:\n",
    "evaluate_detection_performance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T15:13:59.409774Z",
     "iopub.status.busy": "2025-05-25T15:13:59.409509Z",
     "iopub.status.idle": "2025-05-25T15:15:01.649849Z",
     "shell.execute_reply": "2025-05-25T15:15:01.649142Z",
     "shell.execute_reply.started": "2025-05-25T15:13:59.409754Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Edge-enhanced SR sonucu için:\n",
    "evaluate_detection_performance(model, sr_dir=\"/kaggle/working/SRresults_edge\", csv_path=\"results_edge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:06.264088Z",
     "iopub.status.busy": "2025-05-25T15:15:06.263624Z",
     "iopub.status.idle": "2025-05-25T15:15:06.569302Z",
     "shell.execute_reply": "2025-05-25T15:15:06.568592Z",
     "shell.execute_reply.started": "2025-05-25T15:15:06.264064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Detection Results Plotting Function\n",
    "# --------------------------\n",
    "\n",
    "def plot_detection_totals(csv_path=\"detection_results.csv\"):\n",
    "    \"\"\"\n",
    "    Reads a detection results CSV and plots total number of detections\n",
    "    for low-light, super-resolved, and high-light images.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path: Path to the detection results CSV file\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Replace NaN values with 0 for consistency\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate total detections\n",
    "    totals = {\n",
    "        \"Low-light\": int(df[\"low_detections\"].sum()),\n",
    "        \"Super-resolved\": int(df[\"sr_detections\"].sum()),\n",
    "        \"High-light (GT)\": int(df[\"high_detections\"].sum())\n",
    "    }\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(totals.keys(), totals.values(), color=[\"gray\", \"skyblue\", \"lightgreen\"])\n",
    "    plt.title(\"Total Objects Detected by Image Type\")\n",
    "    plt.ylabel(\"Total Number of Detections\")\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_detection_totals(\"detection_results.csv\")\n",
    "plot_detection_totals(\"results_edge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:18.749357Z",
     "iopub.status.busy": "2025-05-25T15:15:18.749074Z",
     "iopub.status.idle": "2025-05-25T15:15:19.551607Z",
     "shell.execute_reply": "2025-05-25T15:15:19.550942Z",
     "shell.execute_reply.started": "2025-05-25T15:15:18.749339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"702.png\")\n",
    "compare_detections(model, \"702.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:23.286455Z",
     "iopub.status.busy": "2025-05-25T15:15:23.286216Z",
     "iopub.status.idle": "2025-05-25T15:15:24.072673Z",
     "shell.execute_reply": "2025-05-25T15:15:24.071948Z",
     "shell.execute_reply.started": "2025-05-25T15:15:23.286440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"5.png\")\n",
    "compare_detections(model, \"5.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:24.384468Z",
     "iopub.status.busy": "2025-05-25T15:15:24.384163Z",
     "iopub.status.idle": "2025-05-25T15:15:25.099360Z",
     "shell.execute_reply": "2025-05-25T15:15:25.098757Z",
     "shell.execute_reply.started": "2025-05-25T15:15:24.384448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"246.png\")\n",
    "compare_detections(model, \"246.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:28.028674Z",
     "iopub.status.busy": "2025-05-25T15:15:28.028429Z",
     "iopub.status.idle": "2025-05-25T15:15:28.784279Z",
     "shell.execute_reply": "2025-05-25T15:15:28.783578Z",
     "shell.execute_reply.started": "2025-05-25T15:15:28.028657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"242.png\")\n",
    "compare_detections(model, \"242.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:28.786059Z",
     "iopub.status.busy": "2025-05-25T15:15:28.785592Z",
     "iopub.status.idle": "2025-05-25T15:15:29.502819Z",
     "shell.execute_reply": "2025-05-25T15:15:29.502201Z",
     "shell.execute_reply.started": "2025-05-25T15:15:28.786038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"240.png\")\n",
    "compare_detections(model, \"240.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:33.002227Z",
     "iopub.status.busy": "2025-05-25T15:15:33.001641Z",
     "iopub.status.idle": "2025-05-25T15:15:33.770826Z",
     "shell.execute_reply": "2025-05-25T15:15:33.770163Z",
     "shell.execute_reply.started": "2025-05-25T15:15:33.002205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"645.png\")\n",
    "compare_detections(model, \"645.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:35.727925Z",
     "iopub.status.busy": "2025-05-25T15:15:35.727660Z",
     "iopub.status.idle": "2025-05-25T15:15:36.516444Z",
     "shell.execute_reply": "2025-05-25T15:15:36.515761Z",
     "shell.execute_reply.started": "2025-05-25T15:15:35.727907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_detections(model, \"781.png\")\n",
    "compare_detections(model, \"781.png\", sr_dir=\"/kaggle/working/SRresults_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T15:15:47.812727Z",
     "iopub.status.busy": "2025-05-25T15:15:47.812140Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r Last.zip /kaggle/working"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2356282,
     "sourceId": 3970170,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7197274,
     "sourceId": 11483406,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7458183,
     "sourceId": 11868352,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
